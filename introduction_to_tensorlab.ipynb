{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Introduction to Tensorlab\n",
    "\n",
    "by Paul Breiding (https://personal-homepages.mis.mpg.de/breiding/, breiding@mis.mpg.de).\n",
    "\n",
    "This notebook is a tutorial for <font style=\"color:rgb(0,88,123)\"> Tensorlab</font>, a MATLAB toolbox for tensor computations. You can download Tensorlab at\n",
    " \n",
    "        https://www.tensorlab.net\n",
    "\n",
    "Tensorlab requires MATLAB 7.9 (R2009b) or higher. To get MATLAB running in jupyter notebook follow the [guide](https://anneurai.net/2015/11/12/matlab-based-ipython-notebooks/) by [Anne Urai](https://anneurai.net). For convenience, I copied her guide here:\n",
    "\n",
    "* Download and install [Anaconda](https://www.continuum.io/downloads). Restart Terminal. Or, if you’d prefer to not get the full Anaconda software, check out this post.\n",
    "* In terminal, type\n",
    "    \"pip install pymatbridge\"\n",
    "    \"pip install matlab_kernel\" and \n",
    "    \"python -m matlab_kernel install\"\n",
    "* Point the kernel to your version of Matlab. I added export\n",
    "\n",
    "        \"MATLAB_EXECUTABLE=/Applications/MATLAB_R2015b.app/bin/matlab\" \n",
    "    \n",
    "    to my .bash_profile file. To do this from Terminal, type echo \n",
    "    \n",
    "        “export MATLAB_EXECUTABLE=/Applications/MATLAB_2015b.app/bin/matlab” >> ~/.bash_profile\n",
    "    \n",
    "    Of course, make sure the location and version of Matlab match yours. Restart terminal or load .bash_profile. Type ipython notebook in Terminal. \n",
    "* You’re now ready to run your notebook! \n",
    "\n",
    "As of August 2018 this did not work with Python 3.6, but it did work with Python 3.5. Here is a [guide](https://conda.io/docs/user-guide/tasks/manage-python.html#using-a-different-version-of-python) on how to switch between different Python version.\n",
    "\n",
    "Tensorlab installation: unzip the files into a folder and add the folder to your current MATLAB session.\n",
    "\n",
    "The pictures in this notebook are taken from the Tensorlab manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "addpath('PATH_TO_THE_TENSORLAB_FOLDER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Tensorlab provides functions for computing with tensors.\n",
    "\n",
    "In this tutorial we will go through the functions for multilinear multiplication and consider algorithms for  computing three types of tensor decompositions:\n",
    "\n",
    "* Multilinear singular value decomposition\n",
    "* Block term decomposition\n",
    "* Canonical polyadic decomposition (CPD)\n",
    "\n",
    "\n",
    "\n",
    "### <font style=\"color:rgb(0,88,123)\"> Multilinear Multiplication</font>\n",
    "\n",
    "\n",
    "Recall that for $S\\in \\mathbb{R}^{n_1\\times \\cdots\\times n_d}$ and $U_i\\in\\mathbb{R}^{m_i \\times n_i}$ the multilinear multiplication is defined as follows: let $e_i$ denote the standard basis vectors and write $A=\\sum s_{i_1,\\ldots,i_d} \\,e_{i_1}\\otimes \\cdots\\otimes e_{i_d}$. Then\n",
    "\n",
    "$$ (U_1,\\cdots,U_d)\\,s := \\sum a_{i_1,\\ldots,i_d} s_{i_1,\\ldots,i_d}\\,(M_1e_{i_1})\\otimes \\cdots\\otimes (M_de_{i_d}).$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S(:,:,1) =\n",
      "\n",
      "    0.8147    0.1270\n",
      "    0.9058    0.9134\n",
      "\n",
      "\n",
      "S(:,:,2) =\n",
      "\n",
      "    0.6324    0.2785\n",
      "    0.0975    0.5469\n",
      "\n",
      "\n",
      "S0(:,:,1) =\n",
      "\n",
      "    1.5188    1.5444    2.3696    2.7507\n",
      "    1.0691    1.2372    1.7094    1.9966\n",
      "    0.8689    0.6823    1.3001    1.4927\n",
      "    0.7419    1.0138    1.2290    1.4479\n",
      "\n",
      "\n",
      "S0(:,:,2) =\n",
      "\n",
      "    1.3400    1.4319    2.1098    2.4548\n",
      "    0.9191    1.1095    1.4821    1.7348\n",
      "    0.7991    0.6830    1.2110    1.3952\n",
      "    0.6127    0.8750    1.0254    1.2110\n",
      "\n",
      "\n",
      "ans =\n",
      "\n",
      "    'S has format 2  2  2 and S0=(U1,U2,U3)S has format 4  4  2'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "% generate a random tensor\n",
    "S = rand(2,2,2) \n",
    "\n",
    "% generate random matrices\n",
    "U1 = rand(4,2); U2 = rand(4,2); U3 = rand(2,2);\n",
    "\n",
    "% multilinear multiplication (U1, U2, U3) S\n",
    "S0 = tmprod(S, {U1, U2, U3}, 1:3) \n",
    "\n",
    "\n",
    "% print the sizes of the two tensors\n",
    "['S has format ' num2str(size(S)) ' and S0=(U1,U2,U3)S has format ' num2str(size(S0))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "\n",
    "\n",
    "### <font style=\"color:rgb(0,88,123)\">Multilinear Singular Value Decomposition (MLSVD)</font>\n",
    "\n",
    "![img](lmlra.svg)\n",
    "    \n",
    "<b><font style=\"color:rgb(152,17,53)\">Reminder:</font></b> the singular value decomposition (SVD) of a matrix $T\\in\\mathbb{R}^{n\\times m}$ ($n\\leq m$): $T = U \\,\\Sigma \\,V^T, \\text{ where } \\Sigma = \\mathrm{diag}(\\sigma_1,\\ldots,\\sigma_m)$ and where $U\\in \\mathbb{R}^{n\\times m}, V\\in\\mathbb{R}^{m\\times m}$ have orthonormal columns and $\\sigma_1\\geq \\cdots\\geq \\sigma_m\\geq 0$ are the singular values. \n",
    "\n",
    "\n",
    "\n",
    "* The rank of $T$ is the number of non-zero singular values.\n",
    "\n",
    "* The best rank-$r$ approximation $S$ to $T$ is $S = U \\,\\mathrm{diag}(\\sigma_1,\\ldots,\\sigma_r,0,\\ldots,0) \\,V^T = WW^TT,$ where $W\\in \\mathbb{R}^{n\\times r}$ is the matrix consisting of the first $r$ columns of $U$.\n",
    "\n",
    "\n",
    "The idea behind MLSVD is to compute the SVDs of the <b><font style=\"color:rgb(152,17,53)\">flattenings</font></b> of a tensor:\n",
    " \n",
    "$$\\text{For } 1\\leq i\\leq d: \\; T\\in\\mathbb{R}^{n_1 \\times \\cdots \\times n_d} \\;\\stackrel{\\text{reshape}}{\\longrightarrow}\\; T_{(i)}\\in\\mathbb{R}^{n_i \\times (\\prod_{j\\neq i} n_j)}.$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "T(:,:,1) =\n",
      "\n",
      "    0.2582    0.2622\n",
      "    0.4087    0.5949\n",
      "    0.5959    0.2622\n",
      "\n",
      "\n",
      "T(:,:,2) =\n",
      "\n",
      "    0.5261    0.5244\n",
      "    0.8174    1.1898\n",
      "    1.1898    0.5244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "% Consider, for instance, the following 3x2x2 tensor T\n",
    "% T will act as a running example throughout this presentation\n",
    "\n",
    "T(:,:,1) = [0.2582 0.2622;0.4087 0.5949; 0.5959 0.2622];\n",
    "T(:,:,2) = [0.5261 0.5244;0.8174 1.1898;1.1898 0.5244]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compute the matricization $T_{(1)}$ and its SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "T_first(:,:,1) =\n",
      "\n",
      "   -0.7464   -0.6728\n",
      "    0.1781   -0.1969\n",
      "    0.0037    0.0000\n",
      "\n",
      "\n",
      "T_first(:,:,2) =\n",
      "\n",
      "   -1.4951   -1.3456\n",
      "    0.3540   -0.3937\n",
      "   -0.0019    0.0000\n",
      "\n",
      "\n",
      "T_second(:,:,1) =\n",
      "\n",
      "   -0.7464   -0.6728\n",
      "    0.1781   -0.1969\n",
      "    0.0037    0.0000\n",
      "\n",
      "\n",
      "T_second(:,:,2) =\n",
      "\n",
      "   -1.4951   -1.3456\n",
      "    0.3540   -0.3937\n",
      "   -0.0019    0.0000\n",
      "\n",
      "\n",
      "ans =\n",
      "\n",
      "    'The frobenius distance between the two transformed tensors is 7.228e-16'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "% the following two scripts do the same thing:\n",
    "\n",
    "% script 1\n",
    "T1 = tens2mat(T, 1); %compute the flattening in the first mode\n",
    "[U Sigma] = svd(T1); %compute the SVD of T1\n",
    "T_first = tmprod(T, {U'}, [1]) %compress T \n",
    "\n",
    "% script 2\n",
    "[Us, S, sv] = mlsvd(T); % Compute the MLSVD \n",
    "U = Us{1}; % extract the first U\n",
    "T_second = tmprod(T, {U'}, [1]) % compress T\n",
    "\n",
    "% compare outputs\n",
    "['The frobenius distance between the two transformed tensors is ' num2str(frob(T_first - T_second))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### <font style=\"color:rgb(0,88,123)\">Definition </font>\n",
    "Let $T\\in \\mathbb{R}^{n_1\\times \\cdots\\times n_d}$. The multilinear rank $(r_1,\\ldots,r_d)$ of $T$ is defined by $r_i:=\\mathrm{rank}(T_{(i)})$.\n",
    "\n",
    "<br>\n",
    "\n",
    "What is the ml-rank of $T$? Let us plot the singular values of the three matricizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for n = 1:3\n",
    "    subplot(1,6,2*n); semilogy(sv{n}, '.-', 'MarkerSize', 25); ylim([1e-4 10]);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "It seems that $T$ is almost of ml-rank $(2,2,1)$. This motivates the following definition.\n",
    "\n",
    "\n",
    "### <font style=\"color:rgb(0,88,123)\">Definition</font>\n",
    "<p>\n",
    "    \n",
    "Let $T\\in \\mathbb{R}^{n_1\\times \\cdots\\times n_d}$ and let the SVD of the $i$-th flattening be $ T_{(i)} = U_i \\Sigma_i, V_i^T.$\n",
    "\n",
    "The rank-$(r_1,\\ldots,r_d)$ low multilinear rank approximation (LMLRA) of $T$ is the tuple \n",
    "\n",
    "$$(W_1,\\ldots,W_d, S)\\in \\mathbb{R}^{n_1\\times r_1}\\times \\cdots\\times \\mathbb{R}^{n_d\\times r_d} \\times \\mathbb{R}^{r_1\\times \\cdots\\times r_d}, \\text{ where }$$\n",
    "\n",
    "* $W_i$ is the matrix consisting of the first $r_i$ columns of $U_i$.\n",
    "* $S = (W_1^T,\\ldots,W_d^T) \\,T$\n",
    "<p>\n",
    "    \n",
    "(so that $W_iW_i^TT_{(i)}$ is the best rank $r_i$-approximation of $T_{(i)}$).\n",
    "\n",
    "<br>\n",
    "\n",
    "Benefit of an $(r_1,\\ldots,r_d)$ LMLRA: storing $\\prod_{i=1}^d r_i + \\sum_{i=1}^d n_ir_i$ numbers vs. storing  $\\prod_{i=1}^d n_i$ many numbers. The next theorem shows the quality of LMLRA.\n",
    "\n",
    "### <font style=\"color:rgb(0,88,123)\">Theorem (Hackbusch)</font>\n",
    "<p>\n",
    "    \n",
    "Let $(W_1,\\ldots,W_d, S)$ be the the rank-$(r_1,\\ldots,r_d)$ LMLRA of $T\\in \\mathbb{R}^{n_1\\times \\cdots\\times n_d}$. Then,\n",
    "\n",
    "$$\\Vert T-(W_1,\\ldots,W_d)\\,S\\Vert \\leq \\sqrt{d}\\,\\min\\limits_{C\\in \\mathbb{R}^{n_1\\times \\cdots\\times n_d} \\text{ has ml-rank } (r_1,\\ldots,r_d)} \\Vert A-C\\Vert.$$\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "Let us compute the rank-$(2,2,1)$ LMLRA of $T$ and see how well $T$ was approximated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ans =\n",
      "\n",
      "    'The relative error of the LMLRA of T is 0.0018884'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "% compute the (2,2,1)-MLSVD approximation\n",
    "[U, S, sv] = mlsvd(T, [2, 2, 1]); \n",
    "\n",
    "%generate the tensor from the tuple (U_1,U_2,U_3,S)\n",
    "B = lmlragen(U,S) ;\n",
    "\n",
    "%compute the relative error of the approximation\n",
    "['The relative error of the LMLRA of T is ' num2str(frob(T-B) / frob(T))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### <font style=\"color:rgb(0,88,123)\">Block Term Decomposition (BTD)</font>\n",
    "\n",
    "\n",
    "![img](btd.svg)\n",
    "\n",
    "    \n",
    "    \n",
    "### <font style=\"color:rgb(0,88,123)\">Definition</font>\n",
    "<p>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Let  $T\\in \\mathbb{R}^{n_1\\times \\cdots\\times n_d}$  and $r = ((r_1^1,\\ldots,r_d^1), \\ldots, (r_1^R,\\ldots,r_d^R))$ be a $R$-tuple of $d$-tuples of positive integers. We call the decomposition $T = T_1 + \\cdots + T_R$ a $r$-block term decomposition (BTD) of $A$, if $\\text{ml-rank}(T_i)=(r_1^i,\\ldots,r_d^i)$. The smallest such $R$ is called the BTD-rank of $T$.\n",
    "\n",
    "<b><font style=\"color:rgb(152,17,53)\">Goal of BTD:</font></b> find the best $r$-block term approximation; i.e. compute\n",
    "\n",
    "$$ \\min_{B \\text{ has an } r-\\text{BTD}}\\Vert T-B\\Vert.$$\n",
    "\n",
    "Unlike for the LMLRA we have no direct method for solving this approximation problem. Tensorlab provides an optimization algorithm for solving this problem. In a nutshell, this algorithm solves the gradient equation of $\\,f(B)=\\frac{1}{2}\\Vert T-B\\Vert^2$ using a Riemann-Newton method. This method requires an initial decomposition (and hence requires specification of the rank $R$). \n",
    "\n",
    "See also [Absil, Mahony, Sepulchre (2008): Optimization Algorithms on Matrix Manifolds.](http://www.eeci-institute.eu/GSC2011/Photos-EECI/EECI-GSC-2011-M5/book_AMS.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ans =\n",
      "\n",
      "    'The relative error of the BTD approximation of T is 4.8128e-13'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "% define size of the tensor T\n",
    "size_tens = [3 2 2]; \n",
    "\n",
    "% define ml-ranks of the decomposition\n",
    "r = {[2 2 2],[2 2 2],[2 2 1]}; \n",
    "\n",
    "% generate a random BTD, which can serve as initial point\n",
    "U = btd_rnd(size_tens, r);\n",
    "\n",
    "% compute a block term approximation of T with initial decomposition U\n",
    "T0 = btd_nls(T, U); \n",
    "\n",
    "% Compare the decomposition with T\n",
    "['The relative error of the BTD approximation of T is ' num2str(frob(T - btdgen(T0)) / frob(T))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "\n",
    "### <font style=\"color:rgb(0,88,123)\">Canonical Polyadic Decomposition (CPD)</font>\n",
    "\n",
    "![img](cpd.svg)\n",
    "    \n",
    "The CPD expresses a tensor $T\\in\\mathbb{R}^{n_1\\times \\cdots \\times n_d}$ as a sum of rank-one tensors: $T = \\sum_{i=1}^R a_1^i\\otimes \\cdots \\otimes a_d^i.$ The smallest $R$, for which such a decomposition is possible, is called the rank of $T$.  Tensorlab's data structure for dealing with CPDs are <b><font style=\"color:rgb(152,17,53)\">cells of factor matrices</font></b>.\n",
    "\n",
    "### <font style=\"color:rgb(0,88,123)\">Definition</font>\n",
    "\n",
    "The factor matrices of the decomposition $T = \\sum_{i=1}^R\\, a_1^i\\otimes \\cdots \\otimes a_d^i$ are $A_1:=  [a_1^1, \\ldots, a_1^R] \\in \\mathbb{R}^{n_1\\times R}, \\,\\ldots,\\, A_d:=  [a_d^1, \\ldots, a_d^R]\\in \\mathbb{R}^{n_d\\times R}.$\n",
    "\n",
    "<br>\n",
    "\n",
    "Let us make an example\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ans(:,:,1) =\n",
      "\n",
      "    0.1735    0.1989    0.0254\n",
      "    0.2597    0.2218    0.0083\n",
      "\n",
      "\n",
      "ans(:,:,2) =\n",
      "\n",
      "    0.0813    0.0939    0.0122\n",
      "    0.1036    0.0890    0.0036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "% define a rank\n",
    "R = 2; \n",
    "\n",
    "% sample random factor matrices with R columns\n",
    "A = rand(2, R); \n",
    "B = rand(3, R); \n",
    "C = rand(2, R); \n",
    "\n",
    "% create the rank-2 2x3x2 tensor with factor matrices A,B,C\n",
    "cpdgen({A, B, C}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Tensorlab's high-level command for computing CPDs is cpd($\\;\\cdot\\;$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "U =\n",
      "\n",
      "  1×3 cell array\n",
      "\n",
      "    [3×3 double]    [2×3 double]    [2×3 double]\n",
      "\n",
      "\n",
      "ans =\n",
      "\n",
      "    'The relative error of the CPD approximation of T is 1.6015e-16'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "% compute a rank-3 cpd of T\n",
    "R = 3;\n",
    "U = cpd(T, R) \n",
    "\n",
    "% compute the relative error\n",
    "['The relative error of the CPD approximation of T is ' num2str(frob(T - cpdgen(U)) / frob(T))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithms for computing the CPD in Tensorlab are\n",
    "\n",
    "* cpd_gevd (a direct method for tensors of order 3)\n",
    "* cpd_als and cpd_nls (optimization algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "U =\n",
      "\n",
      "  1×3 cell array\n",
      "\n",
      "    [3×2 double]    [2×2 double]    [2×2 double]\n",
      "\n",
      "\n",
      "ans =\n",
      "\n",
      "    'Using GEVF the relative error of the CPD approximation of T is 0.0017996'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "% compute the CPD of T via GEVD. The size of T only allows GEVD for ranks at most 2.\n",
    "U = cpd_gevd(T, 2) \n",
    "\n",
    "% compute the relative error\n",
    "['Using GEVF the relative error of the CPD approximation of T is ' num2str(frob(T - cpdgen(U)) / frob(T))] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cpd_gevd computes the CPD via a generalized eigenvalue decomposition. But this method is numerically unstable and therefore should be used carefully; see https://arxiv.org/abs/1807.04159.\n",
    "\n",
    "The optimization algorithms solve the optimization problem\n",
    "\n",
    "$$\\min_{\\text{factor matrices } A_1,\\ldots, A_d} \\; \\frac{1}{2} \\,\\Vert T -  \\sum_{i=1}^R\\, a_1^i\\otimes \\cdots \\otimes a_d^i\\Vert^2.$$\n",
    "\n",
    "* cpd_als sequentially optimizes over the $A_i$.\n",
    "* cpd_nls applies Newton's method to solve the gradient equation. \n",
    "\n",
    "Let us decompose $T$ with cpd_als and cpd_nls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ans =\n",
      "\n",
      "    'Using cpd_nls the relative error is 1.6367e-16'\n",
      "\n",
      "\n",
      "ans =\n",
      "\n",
      "    'Using cpd_als the relative error is 0.00040781'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "R = 3;\n",
    "\n",
    "% use cpd_nls \n",
    "U_nls = cpd(T, R, 'Algorithm', @cpd_nls); \n",
    "\n",
    "% use cpd_als\n",
    "U_als = cpd(T, R, 'Algorithm', @cpd_als);\n",
    "\n",
    "%  compute the relative errors\n",
    "['Using cpd_nls the relative error is ' num2str(frob(T - cpdgen(U_nls)) / frob(T))] \n",
    "\n",
    "['Using cpd_als the relative error is ' num2str(frob(T - cpdgen(U_als)) / frob(T))] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, one can call cpd_nls and cpd_als directly, but one has to pass an intial decomposition. The rank is implicitly defined by the number of columns of the factor matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ans =\n",
      "\n",
      "    'Using cpd_nls the relative error is 1.6882e-16'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "R = 3;\n",
    "\n",
    "% sample a random decomposition U\n",
    "U0 = {rand(3,R), rand(2,R), rand(2,R)}; \n",
    "\n",
    "% compute the CPD of T with starting guess U\n",
    "U = cpd_nls(T, U0); \n",
    "\n",
    "% compute the relative error\n",
    "['Using cpd_nls the relative error is ' num2str(frob(T - cpdgen(U)) / frob(T))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In https://arxiv.org/abs/1709.00033 it was argued that it can be benificial to solve instead the following problem\n",
    "\n",
    "$$\\min_{T_i \\,\\text{ has rank one}} \\; \\frac{1}{2} \\,\\Vert T -  \\sum_{i=1}^R\\, T_i\\Vert.$$\n",
    "\n",
    "In particular, for large differences in the $\\Vert T_i\\Vert$ solving this optimization problem instead of using factor matrices improves the numerical stability as the following experiment shows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "% !!!\n",
    "% for the code in this box to work download the ancillary files at https://arxiv.org/abs/1709.00033 \n",
    "% and add the MATLAB scripts to your session \n",
    "% !!!\n",
    "\n",
    "% define a rank and an array to store the accuracies of the computations\n",
    "R = 6; \n",
    "accuracy = zeros(20, 2);\n",
    "\n",
    "% define scaling 5^i factors for T_i \n",
    "scaling = arrayfun(@(i) 2^i, 1:R); \n",
    "\n",
    "for i = 1:20\n",
    "\n",
    "    % generate a random tensor with the above scaling\n",
    "    Y = cpdgen({rand(13,R) * diag(scaling), rand(11,R), rand(9,R)});\n",
    "\n",
    "    % generate a random intial decomposition\n",
    "    U0 = {rand(13,R), rand(11,R), rand(9,R)};\n",
    "\n",
    "    % compute the CPD with optimization on the factor matrices\n",
    "    U_factor_matrices = cpd_nls(Y, U0); \n",
    "\n",
    "    % compute the CPD with optimization on the rank-one tensors\n",
    "    U_segre = bv_rgn_hr(Y, U0); \n",
    "\n",
    "    % save the errors of the computations\n",
    "    accuracy(i,1) = -log10(frob(Y - cpdgen(U_factor_matrices)) / frob(Y));\n",
    "    accuracy(i,2) = -log10(frob(Y - cpdgen(U_segre)) / frob(Y));\n",
    "    \n",
    "end\n",
    "\n",
    "hold on; \n",
    "histogram(accuracy(:,1)); \n",
    "histogram(accuracy(:,2)); \n",
    "legend('optimization with factor matrices','Riemannian optimization'); \n",
    "xlabel('-log(relative error)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### <font style=\"color:rgb(0,88,123)\">Structured Data Fusion</font>\n",
    "\n",
    "\n",
    "Tensorlab allows to impose structures on the factors in the optimization algorithms. Structure is imposed on factors by transforming variables $z$ into factors $x$ and optimizing over $z$. \n",
    "\n",
    "In Tensorlab 3.0 there are 41 structures implemented, such as\n",
    "\n",
    "* nonnegativity,\n",
    "* orthogonality,\n",
    "* Hankel or\n",
    "* Toeplitz.\n",
    "\n",
    "The user can also write their own structure function. \n",
    "\n",
    "Furthermore, with SDF the user can solve coupled problems.\n",
    "\n",
    "\n",
    "### <b><font style=\"color:rgb(0,88,123)\">Example</font></b>\n",
    "\n",
    "Let us consider the [GeoLife GPS Trajectories data set](https://www.microsoft.com/en-us/download/details.aspx?id=52367&from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fdownloads%2Fb16d359d-d164-469e-9fd4-daa38f2b2e13%2F) from Microsoft Research (also available as Tensorlab demo).\n",
    "\n",
    "The dataset contains the tensor UserLocAct, which has as entries the counts of 164 users in 168 locations doing 5 activities. A CPD of this tensor can be interpreted as the decomposition of the join probability distribution of the random variable (User, Location, Activity) into a mixture of independence models.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ans =\n",
      "\n",
      "    'The relative error of the approximation is 0.4927'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "% load the dataset\n",
    "load('aaai10.uclaf.data.mat'); \n",
    "\n",
    "% compute a rank-2 CPD of the data\n",
    "U = cpd(UserLocAct, 2); \n",
    "\n",
    "% compute the relative error\n",
    "['The relative error of the approximation is ' num2str(frob(UserLocAct - cpdgen(U)) / frob(UserLocAct))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<b><font style=\"color:rgb(152,17,53)\">Problem:</font></b> The factors in the CPD can only be interpreted as independence models, if their entries are <b><font style=\"color:rgb(152,17,53)\">nonnegative</font></b>. Let us impose the structure \"nonnegative\" on the factors in the CPD. In Tensorlab this is done as follows: first one initializes a struct with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "% initialize the model\n",
    "model = struct; \n",
    "\n",
    "% add the data to the model \"nonnegative\"\n",
    "model.factorizations.nonnegative.data = UserLocAct; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the variables are the defined. We start with a rank $R=2$ decomposition. The factors are defined as positive variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 2;\n",
    "model.variables.u   = rand(164,R);  % variable u \n",
    "model.variables.l   = rand(168,R);  % variable l\n",
    "model.variables.a   = rand(5,R);    % variable a\n",
    "\n",
    "model.factors.U   = {'u', @struct_nonneg};  % declare nonnegative factor U dependend on variable u\n",
    "model.factors.L   = {'l', @struct_nonneg};  % declare nonnegative factor L dependend on variable l\n",
    "model.factors.A   = {'a', @struct_nonneg};  % declare nonnegative factor A dependend on variable a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can compute a CPD of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sol = \n",
      "\n",
      "  struct with fields:\n",
      "\n",
      "    variables: [1×1 struct]\n",
      "      factors: [1×1 struct]\n",
      "         info: [1×1 struct]\n",
      "\n",
      "\n",
      "f = \n",
      "\n",
      "  struct with fields:\n",
      "\n",
      "    U: [164×2 double]\n",
      "    L: [168×2 double]\n",
      "    A: [5×2 double]\n",
      "\n",
      "\n",
      "ans =\n",
      "\n",
      "    'The relative error of the approximation is 0.4927'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "% add a CPD to the model.\n",
    "model.factorizations.nonnegative.cpd  = {'U','L','A'}; \n",
    "\n",
    "% solve the model\n",
    "sol = sdf_nls(model)\n",
    "\n",
    "% extract the factors\n",
    "f = sol.factors\n",
    "U = {f.U, f.L, f.A};\n",
    "\n",
    "% compute the relative error\n",
    "['The relative error of the approximation is ' num2str(frob(UserLocAct - cpdgen(U)) / frob(UserLocAct))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Consider now the following problem: we wish to decompose UserLocAct as before, but in addition we would like to compute the coupled interactions between users and users, and locations and users. With SDF it is possible to solve coupled models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%\n",
    "% as above we first define variables and factors\n",
    "%\n",
    "\n",
    "model = struct;\n",
    "\n",
    "% define variables \n",
    "R = 2; \n",
    "model.variables.u   = rand(164,R);   \n",
    "model.variables.l   = rand(168,R);   \n",
    "model.variables.a   = rand(5,R);\n",
    "model.variables.duu   = rand(1,R);  \n",
    "model.variables.dul   = rand(1,R);\n",
    "\n",
    "% define factors \n",
    "model.factors.U   = {'u', @struct_nonneg};   \n",
    "model.factors.L   = {'l', @struct_nonneg};   \n",
    "model.factors.A   = {'a', @struct_nonneg};\n",
    "model.factors.DUU   = {'duu', @struct_nonneg}; \n",
    "model.factors.DUL   = {'dul', @struct_nonneg};\n",
    "\n",
    "%\n",
    "% Instead of one factorization, we simply write three factorizations into the model. \n",
    "%\n",
    "\n",
    "% factorization 1\n",
    "model.factorizations.fac1.data = UserLocAct; \n",
    "model.factorizations.fac1.cpd  = {'U','L','A'}; \n",
    "\n",
    "% factorization 2\n",
    "model.factorizations.fac2.data = UserUser;  \n",
    "model.factorizations.fac2.cpd  = {'U','U','DUU'}; \n",
    "\n",
    "% factorization 3\n",
    "model.factorizations.fac3.data = UserLoc; \n",
    "model.factorizations.fac3.cpd  = {'U','L','DUL'};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now solve the model with sdf_solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ans =\n",
      "\n",
      "    'The relative error in the first factorization is 0.56892'\n",
      "\n",
      "\n",
      "ans =\n",
      "\n",
      "    'The relative error in the second factorization is 0.999'\n",
      "\n",
      "\n",
      "ans =\n",
      "\n",
      "    'The relative error in the third factorization is 0.55084'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "% solve the model\n",
    "sol = sdf_nls(model); \n",
    "\n",
    "% extract the computed factors\n",
    "f = sol.factors; \n",
    "\n",
    "% error of the 1st factorization\n",
    "U1 = {f.U, f.L, f.A};\n",
    "['The relative error in the first factorization is ' num2str(frob(UserLocAct - cpdgen(U1)) / frob(UserLocAct))]\n",
    "\n",
    "\n",
    "% error of the 2nd factorization\n",
    "U2 = {f.U, f.U, f.DUU};\n",
    "['The relative error in the second factorization is ' num2str(frob(UserUser - cpdgen(U2)) / frob(UserUser))]\n",
    "\n",
    "% error of the 3rd factorization\n",
    "U3 = {f.U, f.L, f.DUL};\n",
    "['The relative error in the third factorization is ' num2str(frob(UserLoc - cpdgen(U3)) / frob(UserLoc))] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For more examples, see the Tensorlab Demos at \n",
    "\n",
    "         https://www.tensorlab.net/demos/ \n",
    "\n",
    "(including a long version of the last example). The Tensorlab online manual is available at https://www.tensorlab.net/doc/."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Matlab",
   "language": "matlab",
   "name": "matlab"
  },
  "language_info": {
   "codemirror_mode": "octave",
   "file_extension": ".m",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "matlab",
   "version": "0.15.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
